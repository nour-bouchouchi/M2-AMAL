{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.functional import pad\n",
    "import torch\n",
    "import unicodedata\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "FILE = \"../data/en-fra.txt\"\n",
    "\n",
    "writer = SummaryWriter(\"/tmp/runs/tag-\"+time.asctime())\n",
    "\n",
    "def normalize(s):\n",
    "    return re.sub(' +',' ', \"\".join(c if c in string.ascii_letters else \" \"\n",
    "         for c in unicodedata.normalize('NFD', s.lower().strip())\n",
    "         if  c in string.ascii_letters+\" \"+string.punctuation)).strip()\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Permet de gérer un vocabulaire.\n",
    "\n",
    "    En test, il est possible qu'un mot ne soit pas dans le\n",
    "    vocabulaire : dans ce cas le token \"__OOV__\" est utilisé.\n",
    "    Attention : il faut tenir compte de cela lors de l'apprentissage !\n",
    "\n",
    "    Utilisation:\n",
    "\n",
    "    - en train, utiliser v.get(\"blah\", adding=True) pour que le mot soit ajouté\n",
    "      automatiquement\n",
    "    - en test, utiliser v[\"blah\"] pour récupérer l'ID du mot (ou l'ID de OOV)\n",
    "    \"\"\"\n",
    "    PAD = 0\n",
    "    EOS = 1\n",
    "    SOS = 2\n",
    "    OOVID = 3\n",
    "\n",
    "    def __init__(self, oov: bool):\n",
    "        self.oov = oov\n",
    "        self.id2word = [\"PAD\", \"EOS\", \"SOS\"]\n",
    "        self.word2id = {\"PAD\": Vocabulary.PAD, \"EOS\": Vocabulary.EOS, \"SOS\": Vocabulary.SOS}\n",
    "        if oov:\n",
    "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
    "            self.id2word.append(\"__OOV__\")\n",
    "\n",
    "    def __getitem__(self, word: str):\n",
    "        if self.oov:\n",
    "            return self.word2id.get(word, Vocabulary.OOVID)\n",
    "        return self.word2id[word]\n",
    "\n",
    "    def get(self, word: str, adding=True):\n",
    "        try:\n",
    "            return self.word2id[word]\n",
    "        except KeyError:\n",
    "            if adding:\n",
    "                wordid = len(self.id2word)\n",
    "                self.word2id[word] = wordid\n",
    "                self.id2word.append(word)\n",
    "                return wordid\n",
    "            if self.oov:\n",
    "                return Vocabulary.OOVID\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2word)\n",
    "\n",
    "    def getword(self, idx: int):\n",
    "        if idx < len(self):\n",
    "            return self.id2word[idx]\n",
    "        return None\n",
    "\n",
    "    def getwords(self, idx: List[int]):\n",
    "        return [self.getword(i) for i in idx]\n",
    "\n",
    "\n",
    "\n",
    "class TradDataset():\n",
    "    def __init__(self,data,vocOrig,vocDest,adding=True,max_len=10):\n",
    "        self.sentences =[]\n",
    "        for s in tqdm(data.split(\"\\n\")):\n",
    "            if len(s)<1:continue\n",
    "            orig,dest=map(normalize,s.split(\"\\t\")[:2])\n",
    "            if len(orig)>max_len: continue\n",
    "            self.sentences.append((torch.tensor([vocOrig.get(o) for o in orig.split(\" \")]+[Vocabulary.EOS]),torch.tensor([vocDest.get(o) for o in dest.split(\" \")]+[Vocabulary.EOS])))\n",
    "    def __len__(self):return len(self.sentences)\n",
    "    def __getitem__(self,i): return self.sentences[i]\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    orig,dest = zip(*batch)\n",
    "    o_len = torch.tensor([len(o) for o in orig])\n",
    "    d_len = torch.tensor([len(d) for d in dest])\n",
    "    return pad_sequence(orig),o_len,pad_sequence(dest),d_len\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136521/136521 [00:03<00:00, 34163.26it/s]\n",
      "100%|██████████| 34132/34132 [00:01<00:00, 25433.54it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "with open(FILE) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [lines[x] for x in torch.randperm(len(lines))]\n",
    "idxTrain = int(0.8*len(lines))\n",
    "\n",
    "vocEng = Vocabulary(True)\n",
    "vocFra = Vocabulary(True)\n",
    "MAX_LEN=100\n",
    "BATCH_SIZE=100\n",
    "\n",
    "datatrain = TradDataset(\"\".join(lines[:idxTrain]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "datatest = TradDataset(\"\".join(lines[idxTrain:]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(datatrain, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(datatest, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#  TODO:  Implémenter l'encodeur, le décodeur et la boucle d'apprentissage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_enc, dim_latent_enc, dim_hidden_enc, pad_index):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_emb =  nn.Embedding(vocab_enc, dim_latent_enc, padding_idx=pad_index) \n",
    "        self.enc_gru = nn.GRU(dim_latent_enc, dim_hidden_enc)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_emb = self.enc_emb(x)\n",
    "        _, h_n = self.enc_gru(x_emb)\n",
    "        return h_n\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_dec, dim_latent_dec, dim_hidden_dec, pad_index) :\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_dec = vocab_dec\n",
    "        self.dec_emb =  nn.Embedding(vocab_dec, dim_latent_dec, padding_idx = pad_index) \n",
    "        self.dec_gru = nn.GRU(dim_latent_dec, dim_hidden_dec)\n",
    "        self.decode = nn.Linear(dim_hidden_dec, vocab_dec) \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        emb = self.dec_emb(x)\n",
    "        _, h_n = self.dec_gru(emb, hidden)\n",
    "        dec = self.decode(h_n)   \n",
    "        return h_n, dec \n",
    "    \n",
    "    def generate(self, hidden, lenseq=None, use_teacher_forcing=False, target=None):\n",
    "        sos = Vocabulary.SOS\n",
    "        eos = Vocabulary.EOS\n",
    "\n",
    "        batch_size = hidden.shape[1] \n",
    "                \n",
    "        trad = torch.full((1, batch_size), sos, dtype=torch.long, device=hidden.device)\n",
    "        trad = torch.nn.functional.one_hot(trad, num_classes=self.vocab_dec)\n",
    "        x = torch.full((1, batch_size), sos, dtype=torch.long, device=hidden.device)\n",
    "\n",
    "        ht = hidden \n",
    "        i = 0\n",
    "        cpt_eos = 0\n",
    "        \n",
    "        while lenseq==None or i<lenseq :\n",
    "            ht, dec = self.forward(x, ht)\n",
    "            output = nn.functional.softmax(dec, dim=1)\n",
    "\n",
    "            x = torch.argmax(output, axis = 2).reshape(1,-1)\n",
    "            \n",
    "            if use_teacher_forcing : \n",
    "                trad = torch.cat((trad, output), dim = 0)\n",
    "                x = target[i,:].reshape(1,-1)\n",
    "            else : \n",
    "                trad = torch.cat((trad, output), dim = 0)\n",
    "\n",
    "            cpt_eos += torch.sum(x==eos).item()\n",
    "            if cpt_eos ==  batch_size: \n",
    "                break\n",
    "            i+=1\n",
    "\n",
    "        return trad[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(encoder, decoder, criterion, train_loader, test_loader, teacher_forcing_prob = 0.5 , lr=0.3, epoch = 10 ):\n",
    "\n",
    "    writer = SummaryWriter(\"traduction/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "\n",
    "    parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "    optimizer = torch.optim.Adam(params = parameters, lr = lr)\n",
    "\n",
    "\n",
    "    liste_loss_train = []\n",
    "    liste_loss_val = []\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        \n",
    "        liste_loss_batch = []\n",
    "\n",
    "        for input_seq, idx_pad_input, target_seq, idx_pad_target in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            use_teacher_forcing = True if torch.rand(1).item() < teacher_forcing_prob else False\n",
    "            hidden = encoder(input_seq)\n",
    "            yhat = decoder.generate(hidden, lenseq=torch.max(idx_pad_target), use_teacher_forcing=use_teacher_forcing, target=target_seq)\n",
    "            yhat = torch.nn.functional.pad(yhat,  (0, target_seq.size(1) - yhat.size(1)), value=Vocabulary.PAD).to(dtype=torch.float32)\n",
    "            yhat = torch.transpose(yhat,1,2)\n",
    "\n",
    "            loss = criterion(yhat, target_seq)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                liste_loss_batch.append(loss.item())\n",
    "            \n",
    "        liste_loss_train.append(np.mean(liste_loss_batch))\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            liste_loss_batch = []\n",
    "\n",
    "            for input_seq, idx_pad_input, target_seq, idx_pad_target in tqdm(test_loader):\n",
    "                optimizer.zero_grad()\n",
    "                use_teacher_forcing = True if torch.rand(1).item() < teacher_forcing_prob else False\n",
    "                hidden = encoder(input_seq)\n",
    "                yhat = decoder.generate(hidden, lenseq=torch.max(idx_pad_target), use_teacher_forcing=use_teacher_forcing, target=target_seq)\n",
    "                yhat = torch.nn.functional.pad(yhat,  (0, target_seq.size(1) - yhat.size(1)), value=Vocabulary.PAD).to(dtype=torch.float32)\n",
    "                yhat = torch.transpose(yhat,1,2)\n",
    "\n",
    "                loss = criterion(yhat, target_seq)\n",
    "\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    liste_loss_batch.append(loss.item())\n",
    "                    \n",
    "            liste_loss_val.append(np.mean(liste_loss_batch))\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(liste_loss_train)), liste_loss_train, label='Loss train', color='tab:orange')\n",
    "    plt.plot(np.arange(len(liste_loss_val)), liste_loss_val, label='Loss val', color='tab:blue')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title(\"Loss en train et en validation\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 569/1365 [05:16<07:22,  1.80it/s]\n",
      "  0%|          | 0/10 [05:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (3) to match target batch_size (16).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13501/2433757968.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_latent_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13501/3612218724.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, criterion, train_loader, test_loader, teacher_forcing_prob, lr, epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (3) to match target batch_size (16)."
     ]
    }
   ],
   "source": [
    "vocab_enc = vocEng.__len__()  \n",
    "dim_latent_enc = 10\n",
    "dim_hidden = 5\n",
    "\n",
    "vocab_dec = vocFra.__len__() \n",
    "dim_latent_dec =  5\n",
    "\n",
    "pad_index = Vocabulary.PAD\n",
    "lr = 0.3\n",
    "\n",
    "\n",
    "encoder = Encoder(vocab_enc, dim_latent_enc, dim_hidden, pad_index)\n",
    "decoder = Decoder(vocab_dec, dim_latent_dec, dim_hidden, pad_index)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=Vocabulary.PAD)\n",
    "train(encoder, decoder, criterion, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduction(sentence, encoder, decoder):\n",
    "    x = torch.tensor([vocEng.__getitem__(w) for w in sentence.split()]).reshape(-1,1)\n",
    "    hidden = encoder(x)\n",
    "    trad = decoder.generate(hidden, lenseq=20)\n",
    "    trad = torch.argmax(trad, axis = 2).reshape(-1)\n",
    "    return \" \".join(vocFra.getwords(trad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "sentence = \"hello i love cats and also dogs\"\n",
    "trad = traduction(sentence, encoder, decoder)\n",
    "print(trad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
